# This is the logstash pipeline used in ISSessionsCTF2021. 
# Given the changes in CTFd and the move to dynamic challenges, 
# it likely no longer applies. It is provided here as an example
# and a reference to fast track creating your own logstash parser. 
# :) The true pipeline is in the pipeline directory 
# (called logstash.conf).

input {
  beats {
    port => 5044
  }
}

filter {

  if [log_id] == "submissions" {
    csv {
      separator => ":"
      columns => ["timestamp", "participant_id", "participant_name", "team_id", "team_name", "challenge_id", "challenge_name", "challenge_category", "challenge_value", "submission", "flags_per_minute", "result"]
      target => "event_data"
      remove_field => [ "message" ]
      convert => {
        "challenge_value" => "integer"
        "flags_per_minute" => "integer"
      }
    }
  }

  if [log_id] == "logins" {
    csv {
      separator => ":"
      columns => ["timestamp", "source_ip", "participant_id", "participant_name", "email", "team_id", "team_name", "result"]
      target => "event_data"
      remove_field => [ "message" ]
    }
  }

  if [log_id] == "registrations" {
    csv {
      separator => ":"
      columns => ["timestamp", "source_ip", "participant_id", "participant_name", "email", "result"]
      target => "event_data"
      remove_field => [ "message" ]
    }
  }

  if [log_id] == "hints" {
    csv {
      separator => ":"
      columns => ["timestamp", "participant_id", "participant_name", "team_id", "team_name", "challenge_id", "challenge_name", "challenge_category", "challenge_value", "hint_id", "hint_type", "hint_cost", "result"]
      target => "event_data"
      remove_field => [ "message" ]
      convert => {
        "challenge_value" => "integer"
        "hint_cost" => "integer"
      }
    }
  }

  if [log_id] == "nginx-access" {
    grok {
      match => { "message" => ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[nginx][access][agent]}\""] }
      remove_field => "message"
    }
    mutate {
      add_field => { "read_timestamp" => "%{@timestamp}" }
    }
    date {
      match => [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
      remove_field => "[nginx][access][time]"
    }
    useragent {
      source => "[nginx][access][agent]"
      target => "[nginx][access][user_agent]"
      remove_field => "[nginx][access][agent]"
    }
    geoip {
      source => "[nginx][access][remote_ip]"
      target => "[nginx][access][geoip]"
    }
  }
  
  if [log_id] == "nginx-error" {
    grok {
      match => { "message" => ["%{DATA:[nginx][error][time]} \[%{DATA:[nginx][error][level]}\] %{NUMBER:[nginx][error][pid]}#%{NUMBER:[nginx][error][tid]}: (\*%{NUMBER:[nginx][error][connection_id]} )?%{GREEDYDATA:[nginx][error][message]}"] }
      remove_field => "message"
    }
    mutate {
      rename => { "@timestamp" => "read_timestamp" }
    }
    date {
      match => [ "[nginx][error][time]", "YYYY/MM/dd H:m:s" ]
      remove_field => "[nginx][error][time]"
    }
  }
}

output {
  elasticsearch {
    id => "elasticsearch-output"
    hosts => ["https://es01:9200", "https://es02:9200", "https://es03:9200"]
    index => "ctf-%{[log_id]}-%{+YYYY.MM.dd}"
    user => "logstash_internal"
    password => "${LOGSTASH_INTERNAL_USER_PASS}"
    ssl => true
    cacert => "/usr/share/logstash/config/logstash-tls/ca.crt"
  }
}
